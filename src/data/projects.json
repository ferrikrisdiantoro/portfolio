[
  {
    "title": "SIRESITA | Destination Recommendation System for North Sumatra",
    "description": "Capstone project focusing on building a tourism recommendation system for North Sumatra using two core machine learning techniques: Content-Based Filtering (CBF) and Collaborative Filtering (CF). The models were developed from scratch using TensorFlow and Scikit-learn, without relying on pretrained APIs or external services.",
    "longDescription": "SIRESITA is a comprehensive tourism recommendation platform designed to promote tourism in North Sumatra. It solves the problem of 'choice overload' for tourists by providing personalized destination suggestions. \n\nThe system utilizes a hybrid approach: \n1. **Content-Based Filtering**: Recommends places similar to what a user has liked before based on metadata (tags, categories, location). \n2. **Collaborative Filtering**: Suggests places popular among users with similar taste profiles.\n\nThe application is fully responsive and features a map-based exploration mode, detailed destination pages, and user reviews.",
    "tech": [
      "Python",
      "TensorFlow",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "Keras",
      "TF-IDF",
      "Cosine Similarity",
      "Matplotlib",
      "Seaborn"
    ],
    "features": [
      "Hybrid Recommendation Engine (CBF + CF)",
      "Interactive Map of North Sumatra Tourism",
      "Real-time Itinerary Planner",
      "User Rating & Review System",
      "Admin Dashboard for Tourism Data Management"
    ],
    "type": "Recommender System",
    "category": "recommender-system",
    "link": "/projects/siresita-recommender",
    "thumbnail": "/projects/siresita-recommender/siresita-home.png",
    "gallery": [
      "/projects/siresita-recommender/siresita-home.png"
    ],
    "youtubeUrl": "dQw4w9WgXcQ",
    "demoLink": "https://siresita.sean-andrianto.my.id/",
    "githubLink": "https://github.com/Capstone-Project-CodingCamp2025/machine-learning.git"
  },
  {
    "title": "SIPENDEKAR | AI-Based Road Damage Detection & Prediction",
    "description": "An award-nominated AI system for detecting and predicting road damage using multitask learning with a custom Swin Transformer model. The model outputs multiple predictions including damage type, size, repair time, and material needs from a single image input. I led the machine learning pipeline, including data enrichment, model development, and deployment via Flask API.",
    "tech": [
      "Python",
      "Swin Transformer",
      "Flask",
      "Multitask Learning",
      "Computer Vision",
      "Transfer Learning"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/si-pendekar-road-ai",
    "thumbnail": "/projects/si-pendekar-road-ai/sipendekar-home.png",
    "demoLink": "https://ferrikrisdiantoro.com",
    "githubLink": "https://github.com/Sipendekar/flask-api.git",
    "gallery": [
      "/projects/si-pendekar-road-ai/sipendekar-home.png"
    ]
  },
  {
    "title": "Fruit & Vegetable Classifier + Nutrition Info WebApp",
    "description": "An image classification web app built as a final project for a machine learning course. It uses an ensemble of ResNet and Swin Transformer models to classify 32 classes of fruits and vegetables, providing nutritional facts such as calories, fiber, and vitamins. The ensemble uses SVM as a meta-learner to improve prediction accuracy.",
    "tech": [
      "Python",
      "PyTorch",
      "Swin Transformer",
      "ResNet",
      "SVM",
      "Flask",
      "React",
      "MySQL"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/fruit-vegetable-classifier",
    "thumbnail": "/projects/fruit-vegetable-classifier/fruitsvegtables-home.png",
    "demoLink": "https://ferrikrisdiantoro.pythonanywhere.com",
    "githubLink": "https://github.com/ferrikrisdiantoro/ml-project-image-classification-fruits-vegetables.git",
    "gallery": [
      "/projects/fruit-vegetable-classifier/fruitsvegtables-home.png"
    ]
  },
  {
    "title": "Manggrow.id | AI Plant Assistant & Monitoring",
    "description": "A comprehensive plant monitoring web application integrated with an intelligent AI assistant. The AI uses a RAG system to answer specific gardening questions based on a curated knowledge base. The backend leverages n8n for orchestration, connecting Google Drive, LlamaIndex, Gemini API, and Pinecone vector database.",
    "tech": [
      "Next.js",
      "Node.js",
      "Express.js",
      "n8n",
      "Gemini API",
      "Pinecone",
      "LlamaIndex"
    ],
    "type": "AI Agent & RAG",
    "category": "mlops-automation",
    "link": "/projects/manggrow-id",
    "thumbnail": "/projects/manggrow-id/1.png",
    "demoLink": "https://manggrow.id",
    "githubLink": "https://github.com/yourusername/manggrow-backend",
    "gallery": [
      "/projects/manggrow-id/1.png",
      "/projects/manggrow-id/2.png",
      "/projects/manggrow-id/3.png",
      "/projects/manggrow-id/4.png",
      "/projects/manggrow-id/5.png",
      "/projects/manggrow-id/6.png",
      "/projects/manggrow-id/7.png",
      "/projects/manggrow-id/8.png",
      "/projects/manggrow-id/9.png"
    ]
  },
  {
    "title": "Enterprise Asset Classification | Power Platform + AI",
    "description": "An end-to-end asset management solution for corporate environments. It combines Microsoft Power Apps for the user interface and Power Automate for approval workflows. The core intelligence is powered by n8n and LLMs to automatically classify asset categories based on descriptions, storing data securely in SharePoint.",
    "tech": [
      "Power Apps",
      "Power Automate",
      "SharePoint",
      "n8n",
      "LLM",
      "Microsoft 365"
    ],
    "type": "Business Automation",
    "category": "mlops-automation",
    "link": "/projects/asset-classification-powerapps",
    "thumbnail": "/projects/asset-classification-powerapps/powerapps.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/asset-classification-powerapps/powerapps.png"
    ]
  },
  {
    "title": "YOLOv11 & DeepSORT Speed Estimation | Real-Time Traffic Analytics",
    "description": "A high-performance computer vision application for analyzing traffic flow in real-time. Combines state-of-the-art YOLOv11 object detection with DeepSORT tracking to estimate vehicle speeds from video feeds. Built from scratch with custom PyTorch implementations of YOLOv11 architecture and DeepSORT tracking algorithms, demonstrating deep understanding of modern CV pipelines.",
    "longDescription": "**YOLOv11 & DeepSORT Speed Estimation** is a comprehensive traffic analysis platform that bridges the gap between research notebooks and production-ready applications.\n\nWhat makes this project unique is the **\"From Scratch\"** implementation approach. Instead of relying on opaque high-level libraries, the core logic for the **YOLOv11 Model Architecture** (C3K2, SPPF, PSA blocks) and **DeepSORT Tracker** has been extracted from research notebooks and re-engineered into a clean, modular Python codebase served via a modern web API.\n\n**The system features a dual-stage AI pipeline:**\n1. **Detection & Classification**: Custom PyTorch-based YOLOv11 implementation detects vehicles (cars, motorcycles, trucks) with high precision using advanced architectural components.\n2. **Tracking & Speed Estimation**: DeepSORT algorithm maintains persistent IDs across frames using Kalman Filters and Hungarian matching. Speed is calculated through pixel displacement analysis with perspective correction calibration.\n\n**Key capabilities include:**\n- **For Traffic Engineers**: Real-time speed monitoring, traffic flow analysis, automated violation detection, and comprehensive analytics dashboards.\n- **For Researchers**: Transparent, modular implementation showcasing how raw tensor manipulations translate to production pipelines.\n- **Video Processing**: Automatic FFmpeg transcoding ensures H.264/AAC encoding for seamless browser playback.\n\nThe application features a modern Next.js 14 UI with drag-and-drop video upload, real-time processing status updates via polling, and side-by-side comparison of original vs analyzed footage. The backend uses FastAPI for high-performance async video processing.",
    "tech": [
      "Python",
      "PyTorch",
      "FastAPI",
      "YOLOv11",
      "DeepSORT",
      "OpenCV",
      "NumPy",
      "FilterPy",
      "Scipy",
      "Kalman Filter",
      "Hungarian Algorithm",
      "FFmpeg",
      "Next.js",
      "React",
      "TypeScript",
      "TailwindCSS",
      "Docker",
      "Docker Compose",
      "Uvicorn"
    ],
    "features": [
      "Custom YOLOv11 Implementation from Scratch (C3K2, SPPF, PSA blocks)",
      "DeepSORT Multi-Object Tracking (Kalman + Hungarian Matching)",
      "Real-Time Speed Estimation with Perspective Correction",
      "Automatic Video Transcoding (H.264/AAC for Browser Playback)",
      "Drag & Drop Video Upload Interface",
      "Real-Time Processing Status Updates",
      "Side-by-Side Original vs Analyzed Video Comparison",
      "Modern Responsive UI with Next.js 14",
      "RESTful API with FastAPI",
      "Docker Containerization for Easy Deployment",
      "Modular, Production-Ready Codebase"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/vehicle-speed-estimation",
    "thumbnail": "/projects/vehicle-speed-estimation/1.png",
    "gallery": [
      "/projects/vehicle-speed-estimation/1.png",
      "/projects/vehicle-speed-estimation/2.png",
      "/projects/vehicle-speed-estimation/3.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/yolov11-deepsort-speed-estimation"
  },
  {
    "title": "InsightSphere | Enterprise Finance AI RAG System",
    "description": "An enterprise-grade financial analysis platform powered by RAG (Retrieval-Augmented Generation) technology. Enables financial analysts and consultants to instantly query complex documents (PDFs, Excel, Reports) and receive accurate, context-aware insights. The system supports multi-persona AI responses with ultra-fast inference powered by Groq and ChromaDB vector storage.",
    "longDescription": "**InsightSphere** is a comprehensive financial intelligence platform that transforms static financial reports into interactive knowledge bases through advanced RAG technology.\n\nThe system enables analysts to chat directly with uploaded documents, asking specific questions like \"What is the Q2 Year-over-Year growth?\" and receiving answers cited from the source. It implements a sophisticated multi-persona AI system, allowing users to switch between **Consultant**, **Neutral**, and **Casual** modes for tailored responses.\n\n**The platform features a dual-layer architecture:**\n1. **Ingestion Engine**: Documents are parsed (PDF, Docx, PPTX, Excel), split into semantic chunks, embedded using sentence-transformers, and stored in ChromaDB for O(1) retrieval.\n2. **RAG Inference Core**: User queries are embedded, top-k relevant chunks are retrieved from the vector store, and fed into Groq Llama-3 for ultra-fast, context-aware response generation.\n\n**Key capabilities include:**\n- **For Analysts**: Intelligent document chat with source citations, multi-format support (PDF, Excel, PPTX, Docx), persona-based AI responses, and automated report export to PowerPoint/Excel.\n- **For Administrators**: Real-time system health monitoring (LLM API, Vector Store, Backend), vector database management, pre-warm embeddings, document chunk oversight, and secure local deployment via Docker.\n\nThe application features a modern React + TypeScript UI powered by Vite, with TailwindCSS for styling and Lucide icons. The backend uses FastAPI for high-performance async API serving with LangChain orchestration.",
    "tech": [
      "Python",
      "FastAPI",
      "Groq API",
      "LlamaIndex",
      "LangChain",
      "ChromaDB",
      "FAISS",
      "Sentence Transformers",
      "PyPDF2",
      "Pandas",
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "Framer Motion",
      "Lucide Icons",
      "Docker",
      "Docker Compose",
      "Gunicorn",
      "Uvicorn"
    ],
    "features": [
      "Advanced RAG System with Groq Llama-3 (Ultra-Fast Inference)",
      "Multi-Format Document Ingestion (PDF, Excel, PPTX, Docx)",
      "Intelligent Semantic Chunking & Vector Storage (ChromaDB/FAISS)",
      "Multi-Persona AI Responses (Consultant/Neutral/Casual)",
      "Source-Cited Answers with Document References",
      "Automated Report Export (PowerPoint & Excel)",
      "Real-time System Health Monitoring Dashboard",
      "Vector Database Management & Pre-Warming",
      "Secure Local Deployment with Docker",
      "Responsive Modern UI with Dark Mode Support",
      "High-Performance Async API with FastAPI",
      "LangChain Orchestration for RAG Pipeline"
    ],
    "type": "GenAI & LLM",
    "category": "nlp-genai",
    "link": "/projects/finance-ai-agent",
    "thumbnail": "/projects/finance-ai-agent/1.png",
    "gallery": [
      "/projects/finance-ai-agent/1.png",
      "/projects/finance-ai-agent/2.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/enterprise-finance-ai"
  },
  {
    "title": "DERMA-DFU.ID | AI-Powered Diabetic Foot Ulcer Triage System",
    "description": "A comprehensive medical AI web application for intelligent screening and triage of diabetic foot ulcers. Leverages state-of-the-art deep learning models for infection detection, ischemia assessment, and automated wound measurement, providing evidence-based clinical decision support for rural healthcare workers and patients.",
    "longDescription": "**DERMA-DFU.ID** is an advanced healthcare platform designed to transform diabetic foot ulcer management through artificial intelligence. Built for resource-constrained settings, it empowers frontline healthcare workers and diabetes patients with instant, evidence-based triage capabilities.\n\nThe system performs multi-modal AI analysis combining **Classification** and **Segmentation**:\n1. **4-Class Deep Learning Classifier**: Detects None, Infection, Ischaemia, or Both conditions using a custom-trained EfficientNet-style CNN model.\n2. **U-Net Wound Segmentation**: Automatically measures wound area in pixels and converts to cm² using calibrated scale measurements.\n3. **Clinical Rule Engine**: Integrates AI predictions with critical clinical signs (fever, pulse, odor, pain) to generate safety-first triage decisions.\n\n**The Triage System (RED-YELLOW-GREEN)**:\n- **RED (≤48h Referral)**: Danger signs detected (fever, spreading redness, no pulse, severe kidney disease + infection) OR high ischaemia probability OR AI detects \"Both\" conditions.\n- **YELLOW (≤72h Tele-consult)**: Small wound with stable vitals OR mild infection/ischaemia detected by AI.\n- **GREEN (Self-care + Education)**: Pre-ulcer stage or minimal wound with no concerning features.\n\n**Key Technical Innovations**:\n- **100% Client-Side AI Inference**: All ML models run in-browser via ONNX Runtime WebAssembly—no patient data ever leaves the device, ensuring HIPAA-level privacy.\n- **Interactive Calibration System**: Two-point click measurement on ruler/card images for precise wound size calculation (mm/px scaling).\n- **Comprehensive Dashboard Analytics**: Performance indicators including time-to-referral, completion rates, photo adherence, and triage distribution.\n- **Tele-referral Integration**: Direct scheduling with specialists, real-time chat with doctors, and full digital health record management.\n\nThe application features a responsive React UI with dark mode, bilingual support (Indonesian/English), offline-capable PWA architecture, and Supabase backend with Row-Level Security for multi-tenant patient management.",
    "tech": [
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "shadcn/ui",
      "Radix UI",
      "ONNX Runtime Web",
      "Supabase",
      "PostgreSQL",
      "TanStack Query",
      "React Router DOM",
      "Deep Learning",
      "Computer Vision",
      "U-Net Segmentation",
      "EfficientNet",
      "TensorFlow (Model Training)",
      "Lucide Icons",
      "Sonner",
      "Zod"
    ],
    "features": [
      "AI-Powered 4-Class Infection/Ischaemia Detection",
      "Automated Wound Segmentation & Area Measurement (U-Net)",
      "Interactive Two-Point Calibration for Metric Scaling (mm/px)",
      "Evidence-Based RED-YELLOW-GREEN Triage System",
      "100% Client-Side Inference (Privacy-First, No Data Upload)",
      "Clinical Decision Support with Danger Sign Detection",
      "Real-Time Tele-Consultation Chat with Doctors",
      "Comprehensive Patient History & Analytics Dashboard",
      "Performance Metrics (Time-to-Referral, Completion Rates)",
      "Bilingual Interface (Indonesian/English)",
      "Responsive PWA with Offline Capability",
      "Role-Based Access Control (Patient/Admin/Doctor)",
      "Supabase Authentication & Row-Level Security (RLS)",
      "Photo Storage with Secure Public URLs",
      "CSV Export for Clinical Reporting",
      "Interactive Education Module (Guidelines, First Aid)",
      "Dark Mode Support"
    ],
    "type": "Healthcare AI",
    "category": "computer-vision",
    "link": "/projects/derma-dfu",
    "thumbnail": "/projects/derma-dfu/1.png",
    "demoLink": "https://derma-dfu.id",
    "githubLink": "https://github.com/rezayuridian-cell/derma-bantu-sehat",
    "gallery": [
      "/projects/derma-dfu/1.png",
      "/projects/derma-dfu/2.png",
      "/projects/derma-dfu/3.png",
      "/projects/derma-dfu/4.png",
      "/projects/derma-dfu/5.png"
    ]
  },
  {
    "title": "River Gauge AI | Intelligent Water Level Monitoring System",
    "description": "A production-grade computer vision system for automated hydrological monitoring. Leverages YOLOv8 object detection to identify and read water gauge markings from RTSP video streams or uploaded footage. Features intelligent waterline detection using texture analysis and robust tick fitting algorithms, with real-time alerting for critical water levels.",
    "longDescription": "**River Gauge AI** is an enterprise-ready platform designed to automate the monitoring of water levels in rivers, dams, and reservoirs. It eliminates the need for manual gauge readings by providing 24/7 automated detection with visual verification.\n\nThe system processes video feeds (RTSP streams or uploaded files) and uses advanced computer vision to detect staff gauges, identify percentage tick marks, and measure the exact water surface level. Each reading is calibrated to real-world elevation values and compared against configurable Yellow/Red alert thresholds.\n\n**The AI pipeline consists of four stages:**\n1. **Object Detection**: YOLOv8 model trained to detect percentage ticks (0%, 10%, 20%...100%) and staff gauge boards\n2. **ROI Extraction**: Automatically crops the region of interest around detected gauges with smart padding\n3. **Waterline Detection**: Multi-algorithm approach combining texture energy analysis, gradient detection, and side-aware processing to identify the water surface\n4. **Elevation Calculation**: Robust linear regression fitting with rate-limiting to prevent false spikes\n\n**Key capabilities include:**\n- **For Operators**: Real-time monitoring dashboard with live video feeds, configurable alert zones (Yellow/Red), and visual overlays showing detected ticks and water levels\n- **For Analysts**: Historical data visualization with Chart.js, exportable reports, and video playback with synchronized data\n- **For Engineers**: Multi-project management, custom calibration parameters (base elevation low/high), and RTSP stream integration\n\nThe application features a modern React dashboard with TypeScript, supporting multiple concurrent monitoring sites. The backend uses FastAPI with async processing, SQLAlchemy for persistence, and FFmpeg for video handling. The CV engine leverages OpenCV with optional OpenCL acceleration and supports both CPU and GPU (CUDA) inference.\n\n**Advanced Features:**\n- Rate-limiting algorithm to filter false readings (max cm/sec threshold)\n- Smart ROI zoom with texture-aware waterline detection\n- Hold-last-known-good fallback for temporary detection failures\n- Alert level visualization with color-coded overlays (Green/Yellow/Red zones)\n- Docker containerization with docker-compose orchestration",
    "tech": [
      "Python",
      "FastAPI",
      "Uvicorn",
      "YOLOv8",
      "Ultralytics",
      "OpenCV",
      "NumPy",
      "PyTorch",
      "SQLAlchemy",
      "SQLite",
      "FFmpeg",
      "Pandas",
      "React",
      "TypeScript",
      "Vite",
      "Vanilla CSS",
      "Chart.js",
      "React Router DOM",
      "Lucide Icons",
      "Docker",
      "Docker Compose",
      "CUDA"
    ],
    "features": [
      "YOLOv8-Based Gauge Detection (Tick Mark Recognition)",
      "Intelligent Waterline Detection (Texture + Gradient Analysis)",
      "Real-time RTSP Stream Processing",
      "Multi-Project Dashboard (Manage Multiple Monitoring Sites)",
      "Configurable Alert System (Yellow/Red Thresholds)",
      "Historical Data Visualization (Chart.js Trends)",
      "Rate-Limiting Algorithm (Prevent False Spikes)",
      "ROI Auto-Cropping with Smart Padding",
      "Video Playback with Synchronized Data",
      "Visual Overlays (Detection Boxes, Water Level Lines)",
      "Elevation Calibration (Base Low/High Configuration)",
      "Hold-Last-Known-Good Fallback Logic",
      "Responsive Modern UI with Dark Theme",
      "GPU/CUDA Support with CPU Fallback",
      "Docker Containerization",
      "FFmpeg Video Processing Integration"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/water-scale-monitor",
    "thumbnail": "/projects/water-scale-monitor/1.png",
    "gallery": [
      "/projects/water-scale-monitor/1.png",
      "/projects/water-scale-monitor/2.png",
      "/projects/water-scale-monitor/3.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/river-gauge-vision"
  },
  {
    "title": "Product Demand Forecasting",
    "description": "A predictive analytics project using time series forecasting to predict future product sales. The model utilizes LSTM (Long Short-Term Memory) networks built with TensorFlow to analyze historical data and forecast trends.",
    "tech": [
      "Python",
      "TensorFlow",
      "LSTM",
      "Pandas",
      "Matplotlib",
      "Time Series"
    ],
    "type": "Predictive Analytics",
    "category": "data-science",
    "link": "/projects/demand-forecasting",
    "thumbnail": "/projects/demand-forecasting/demand.png",
    "demoLink": "#",
    "githubLink": "https://github.com/yourusername/sales-forecasting-lstm",
    "gallery": [
      "/projects/demand-forecasting/demand.png"
    ]
  },
  {
    "title": "End-to-End MLOps Workflow",
    "description": "A demonstration of a complete Machine Learning Operations (MLOps) pipeline. It integrates MLflow for experiment tracking, DagsHub for collaboration, Docker for containerization, and Grafana/Prometheus for system monitoring.",
    "tech": [
      "MLflow",
      "Docker",
      "Grafana",
      "Prometheus",
      "DagsHub",
      "CI/CD"
    ],
    "type": "MLOps",
    "category": "mlops-automation",
    "link": "/projects/mlops-workflow",
    "thumbnail": "/projects/mlops-workflow/mlflow.png",
    "demoLink": "#",
    "githubLink": "https://github.com/yourusername/mlops-pipeline",
    "gallery": [
      "/projects/mlops-workflow/mlflow.png"
    ]
  },
  {
    "title": "Face Recognition Attendance System | Anti-Spoofing Security",
    "description": "An enterprise-grade automated attendance platform designed for universities and corporations. Leverages AI-powered face recognition with advanced anti-spoofing technology to provide secure, contactless, and instant verification. The system combines YOLOv11 for face detection and InsightFace for recognition, featuring active liveness detection to prevent photo and video replay attacks.",
    "longDescription": "**Face Recognition Attendance System** is a comprehensive platform that modernizes classroom and organizational attendance through state-of-the-art AI technology.\n\nAt its core is a powerful **Anti-Spoofing Engine** that analyzes texture patterns (LBP), motion, color distribution, and moire artifacts to differentiate real faces from photos or digital screens. This ensures the highest integrity of attendance records.\n\n**The system features a dual-stage AI pipeline:**\n1. **Detection & Liveness Verification**: YOLOv11-Face detects faces and custom CV algorithms verify liveness through micro-movement analysis (blinking, breathing) and texture analysis before processing.\n2. **Face Recognition**: InsightFace (ArcFace) extracts 512-dimensional vector embeddings and matches them against the database using cosine similarity for high-confidence identification.\n\n**Key capabilities include:**\n- **For Lecturers**: Live attendance feed with real-time visual feedback, class scheduling, student enrollment management, and automated attendance reports.\n- **For Administrators**: Centralized user management, system analytics, performance monitoring, and secure biometric data management.\n- **Security Features**: Multi-layer anti-spoofing (texture, motion, depth analysis), encrypted face embeddings, and audit logging.\n\nThe application features a modern, responsive React UI with premium design, real-time WebSocket updates, and comprehensive admin dashboards. The backend uses Flask with SQLAlchemy for robust data persistence.",
    "tech": [
      "Python",
      "Flask",
      "React",
      "Vite",
      "TailwindCSS",
      "YOLOv11",
      "InsightFace",
      "ArcFace",
      "TensorFlow",
      "OpenCV",
      "NumPy",
      "PyTorch",
      "SQLAlchemy",
      "Socket.IO",
      "MySQL",
      "Docker",
      "Gunicorn"
    ],
    "features": [
      "Advanced Anti-Spoofing Detection (Texture, Motion, Depth Analysis)",
      "Active Liveness Detection (Blink & Micro-Movement)",
      "Real-time Face Recognition with InsightFace (512D Embeddings)",
      "Live Attendance Feed with WebSocket Updates",
      "Class & Student Management Dashboard",
      "Automated Attendance Reports & Export (Excel)",
      "Admin Panel (User, Class, Subject Management)",
      "Secure Face Enrollment & Biometric Storage",
      "System Analytics & Performance Monitoring",
      "Responsive Modern UI with Dark Mode Support",
      "Docker Containerization for Easy Deployment"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/face-recognition-attendance",
    "thumbnail": "/projects/face-recognition-attendance/1.png",
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/face-recognition-attendance-app",
    "gallery": [
      "/projects/face-recognition-attendance/1.png",
      "/projects/face-recognition-attendance/2.png",
      "/projects/face-recognition-attendance/3.png",
      "/projects/face-recognition-attendance/4.png",
      "/projects/face-recognition-attendance/5.png",
      "/projects/face-recognition-attendance/6.png",
      "/projects/face-recognition-attendance/7.png",
      "/projects/face-recognition-attendance/8.png",
      "/projects/face-recognition-attendance/9.png"
    ]
  },
  {
    "title": "Static QnA Chatbot",
    "description": "An NLP-based chatbot that answers user questions from a predefined QnA document. It uses text preprocessing, TF-IDF, and cosine similarity to retrieve the most relevant answers. The frontend is built with ReactJS + TailwindCSS and the backend uses NodeJS.",
    "tech": [
      "TensorFlow",
      "ReactJS",
      "TailwindCSS",
      "NodeJS",
      "Cosine Similarity",
      "NLP"
    ],
    "type": "NLP",
    "category": "nlp-genai",
    "link": "/projects/qna-chatbot-static",
    "thumbnail": "/projects/qna-chatbot-static/qna.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/qna-chatbot-static/qna.png"
    ]
  },
  {
    "title": "Chat With Your Documents | RAG System",
    "description": "A Retrieval-Augmented Generation (RAG) application that allows users to upload documents and chat with their content. It uses LangChain, Pinecone, and Groq LLaMA API for semantic retrieval, with a Streamlit UI and FastAPI backend.",
    "tech": [
      "LangChain",
      "Pinecone",
      "Groq API",
      "LLaMA",
      "FastAPI",
      "Streamlit"
    ],
    "type": "RAG System",
    "category": "nlp-genai",
    "link": "/projects/chat-with-documents",
    "thumbnail": "/projects/chat-with-documents/cwyd.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/chat-with-documents/cwyd.png"
    ]
  },
  {
    "title": "Virtual Try On | Nail Polish Segmentation",
    "description": "A virtual try-on web app for nail polish that uses image segmentation to detect nail regions and apply color effects in real time. The model is built with TensorFlow and Keras, and the UI is implemented with Streamlit.",
    "tech": [
      "TensorFlow",
      "Keras",
      "Image Segmentation",
      "Streamlit"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/virtual-tryon-nail",
    "thumbnail": "/projects/virtual-tryon-nail/nails.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/virtual-tryon-nail/nails.png"
    ]
  },
  {
    "title": "Waste Classification | Organic vs Recycle",
    "description": "An image classification project that classifies waste into Organic or Recycle categories. The model is built using TensorFlow and Keras, while Streamlit is used to display predictions and probability charts.",
    "tech": [
      "TensorFlow",
      "Keras",
      "Streamlit",
      "Image Classification"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/waste-classification",
    "thumbnail": "/projects/waste-classification/waste.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/waste-classification/waste.png"
    ]
  },
  {
    "title": "Playstore App Comment Sentiment Analysis",
    "description": "A text classification model for categorizing Playstore app reviews into Positive, Negative, and Neutral sentiments. The project is developed in Google Colab using TensorFlow and an LSTM-based architecture.",
    "tech": [
      "TensorFlow",
      "Keras",
      "LSTM",
      "NLP",
      "Colab"
    ],
    "type": "NLP",
    "category": "nlp-genai",
    "link": "/projects/playstore-sentiment",
    "thumbnail": "/projects/playstore-sentiment/sentiment.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/playstore-sentiment/sentiment.png"
    ]
  },
  {
    "title": "Customer Service AI Chatbot | RAG Automation",
    "description": "A customer service chatbot built using a RAG system orchestrated in n8n automation workflows. It answers user questions based on a curated internal knowledge base, combining LLMs with deterministic retrieval.",
    "tech": [
      "n8n",
      "RAG System",
      "NodeJS",
      "LangChain",
      "LLM"
    ],
    "type": "AI Automation",
    "category": "mlops-automation",
    "link": "/projects/customer-service-chatbot",
    "thumbnail": "/projects/customer-service-chatbot/chatbot.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/customer-service-chatbot/chatbot.png"
    ]
  },
  {
    "title": "Concrete Defect Detection | Enterprise Structural Health Monitoring",
    "description": "An enterprise-grade AI platform for automated civil infrastructure inspection. Leverages advanced Computer Vision to detect, classify, and assess the severity of 5 types of structural defects in concrete columns. Designed for civil engineers and inspectors to transform manual visual inspections into digital, auditable, and quantifiable workflows.",
    "longDescription": "**Concrete Defect Detection** is a comprehensive structural health monitoring system built for the construction and civil engineering industries. It automates the inspection process for concrete infrastructure, providing rapid and accurate defect analysis.\n\nThe platform identifies **5 critical damage types**: Crack, Spalling, Honeycomb, Segregation, and Corrosion. Each detection is automatically classified by severity (Minor, Moderate, Severe) based on damage area ratios and visual characteristics.\n\n**Key capabilities include:**\n1. **Multi-Class Detection**: High-precision YOLO/CNN model optimized with ONNX Runtime for CPU inference\n2. **Severity Assessment**: Intelligent severity grading using area analysis and damage-specific thresholds\n3. **Smart Recommendations**: ISO/ACI-compliant repair solutions based on damage type and severity\n4. **BIM Integration**: Exports IFC Overlay JSON for seamless integration with Autodesk Revit/Dynamo\n5. **History & Analytics**: Tracks defect progression over time with filtering and analytics dashboard\n\nThe system features a fully responsive React UI with stunning visual design, dark mode, and interactive data cards powered by Framer Motion. The backend uses FastAPI for high-performance async inference.",
    "tech": [
      "Python",
      "FastAPI",
      "ONNX Runtime",
      "Computer Vision",
      "YOLO",
      "OpenCV",
      "NumPy",
      "Pillow",
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "Framer Motion"
    ],
    "features": [
      "Multi-Class Defect Detection (5 Damage Types)",
      "Intelligent Severity Grading (Minor/Moderate/Severe)",
      "ISO/ACI-Standard Repair Recommendations",
      "BIM Integration (IFC Overlay Export for Revit)",
      "Defect History & Analytics Dashboard",
      "Responsive Modern UI with Dark Mode",
      "High-Performance CPU Inference with ONNX",
      "JSON-Based Storage (Scalable to PostgreSQL)"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/concrete-defect-detection",
    "thumbnail": "/projects/concrete-defect-detection/1.png",
    "gallery": [
      "/projects/concrete-defect-detection/1.png",
      "/projects/concrete-defect-detection/2.png",
      "/projects/concrete-defect-detection/3.png",
      "/projects/concrete-defect-detection/4.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/concrete-defect-detection"
  },
  {
    "title": "StockAI - IDX Prediction Platform | AI-Powered Stock Market Analysis",
    "description": "An enterprise-grade financial analytics platform for predicting stock movements on the Indonesia Stock Exchange (IDX). Combines Machine Learning with Bandar Analysis (Broker Accumulation) to identify high-probability trading signals. Designed for traders and analysts to transform raw stock data into actionable insights through a modern, responsive dashboard.",
    "longDescription": "**StockAI** is a comprehensive stock market intelligence system built for the Indonesian financial market. It automates the analysis of daily market snapshots, broker activities, and technical indicators to generate actionable trading signals.\n\nThe platform processes daily market data and analyzes broker accumulation patterns (\"Bandarology\") to detect smart money movements. Each stock is assigned a Machine Learning probability score indicating the likelihood of price increases, combined with automated explanation generation.\n\n**Key capabilities include:**\n1. **Smart Signal Detection**: Automatically identifies stocks with BUY or STRONG SELL signals based on ML probability and technical indicators\n2. **Bandar Accumulation Analysis**: Visualizes top buyer concentration to detect institutional money movements\n3. **ML Probability Scoring**: XGBoost/Sklearn-powered inference engine assigns `prob_up` scores to every stock\n4. **Backtesting Engine**: Verify strategy performance against historical data with customizable date ranges\n5. **Real-time Filtering**: Filter opportunities by Threshold %, Broker, Price Range, and Signal Type\n6. **Automated Explanations**: Human-readable reasons for every signal (e.g., \"Volume sangat padat\", \"Ada dominasi Broker X\")\n\nThe system features a fully responsive React UI with modern design, dark mode support, and real-time data tables. The backend uses FastAPI for high-performance async API serving with NaN/Inf-safe JSON responses.",
    "tech": [
      "Python",
      "FastAPI",
      "Uvicorn",
      "Pandas",
      "NumPy",
      "Scikit-learn",
      "XGBoost",
      "Joblib",
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "React Router DOM",
      "Lucide Icons",
      "Docker",
      "GitHub Actions"
    ],
    "features": [
      "ML-Powered Stock Movement Prediction (XGBoost)",
      "Broker Accumulation Analysis (Bandarology)",
      "Smart Signal Detection (BUY/STRONG SELL)",
      "Probability Scoring for Every Stock (prob_up)",
      "Backtesting Engine with Historical Data",
      "Real-time Filtering (Threshold, Broker, Price Range)",
      "Automated Signal Explanations",
      "Responsive Modern UI with Dark Mode",
      "High-Performance FastAPI Backend",
      "NaN/Inf-Safe JSON Responses",
      "CI/CD Pipeline with GitHub Actions",
      "Docker & Docker Compose Support"
    ],
    "type": "Machine Learning",
    "category": "data-science",
    "link": "/projects/stockai-idx-prediction",
    "thumbnail": "/projects/stockai-idx-prediction/1.png",
    "gallery": [
      "/projects/stockai-idx-prediction/1.png",
      "/projects/stockai-idx-prediction/2.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/idx-smallcap-screener"
  }
]