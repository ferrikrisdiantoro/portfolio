[
  {
    "title": "SIRESITA | Destination Recommendation System for North Sumatra",
    "description": "Capstone project focusing on building a tourism recommendation system for North Sumatra using two core machine learning techniques: Content-Based Filtering (CBF) and Collaborative Filtering (CF). The models were developed from scratch using TensorFlow and Scikit-learn, without relying on pretrained APIs or external services.",
    "longDescription": "SIRESITA is a comprehensive tourism recommendation platform designed to promote tourism in North Sumatra. It solves the problem of 'choice overload' for tourists by providing personalized destination suggestions. \n\nThe system utilizes a hybrid approach: \n1. **Content-Based Filtering**: Recommends places similar to what a user has liked before based on metadata (tags, categories, location). \n2. **Collaborative Filtering**: Suggests places popular among users with similar taste profiles.\n\nThe application is fully responsive and features a map-based exploration mode, detailed destination pages, and user reviews.",
    "tech": [
      "Python",
      "TensorFlow",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "Keras",
      "TF-IDF",
      "Cosine Similarity",
      "Matplotlib",
      "Seaborn"
    ],
    "features": [
      "Hybrid Recommendation Engine (CBF + CF)",
      "Interactive Map of North Sumatra Tourism",
      "Real-time Itinerary Planner",
      "User Rating & Review System",
      "Admin Dashboard for Tourism Data Management"
    ],
    "type": "Recommender System",
    "category": "recommender-system",
    "link": "/projects/siresita-recommender",
    "thumbnail": "/projects/siresita-recommender/siresita-home.png",
    "gallery": [
      "/projects/siresita-recommender/siresita-home.png"
    ],
    "youtubeUrl": "dQw4w9WgXcQ",
    "demoLink": "https://siresita.sean-andrianto.my.id/",
    "githubLink": "https://github.com/Capstone-Project-CodingCamp2025/machine-learning.git"
  },
  {
    "title": "SIPENDEKAR | AI-Based Road Damage Detection & Prediction",
    "description": "An award-nominated AI system for detecting and predicting road damage using multitask learning with a custom Swin Transformer model. The model outputs multiple predictions including damage type, size, repair time, and material needs from a single image input. I led the machine learning pipeline, including data enrichment, model development, and deployment via Flask API.",
    "tech": [
      "Python",
      "Swin Transformer",
      "Flask",
      "Multitask Learning",
      "Computer Vision",
      "Transfer Learning"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/si-pendekar-road-ai",
    "thumbnail": "/projects/si-pendekar-road-ai/sipendekar-home.png",
    "demoLink": "https://ferrikrisdiantoro.com",
    "githubLink": "https://github.com/Sipendekar/flask-api.git",
    "gallery": [
      "/projects/si-pendekar-road-ai/sipendekar-home.png"
    ]
  },
  {
    "title": "Fruit & Vegetable Classifier + Nutrition Info WebApp",
    "description": "An image classification web app built as a final project for a machine learning course. It uses an ensemble of ResNet and Swin Transformer models to classify 32 classes of fruits and vegetables, providing nutritional facts such as calories, fiber, and vitamins. The ensemble uses SVM as a meta-learner to improve prediction accuracy.",
    "tech": [
      "Python",
      "PyTorch",
      "Swin Transformer",
      "ResNet",
      "SVM",
      "Flask",
      "React",
      "MySQL"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/fruit-vegetable-classifier",
    "thumbnail": "/projects/fruit-vegetable-classifier/fruitsvegtables-home.png",
    "demoLink": "https://ferrikrisdiantoro.pythonanywhere.com",
    "githubLink": "https://github.com/ferrikrisdiantoro/ml-project-image-classification-fruits-vegetables.git",
    "gallery": [
      "/projects/fruit-vegetable-classifier/fruitsvegtables-home.png"
    ]
  },
  {
    "title": "Manggrow.id | AI Plant Assistant & Internship Management",
    "description": "A comprehensive plant monitoring and internship management web application integrated with an intelligent AI assistant. The AI uses a RAG system to answer specific gardening and internship questions based on a curated knowledge base. The backend leverages n8n for orchestration, connecting Supabase, and integrates AI-powered conversational agents.",
    "longDescription": "**Manggrow Web Platform** is a comprehensive ecosystem designed for both plant enthusiasts (gardeners) and administrative teams managing internships.\n\nThe platform solves the problem of scattered information and manual tracking by providing:\n1. **Smart Garden Helper (AI Chatbot)**: 24/7 consultation with an AI Assistant powered by a RAG (Retrieval-Augmented Generation) system. Users can ask about plant problems, care tips, and fertilizer recommendations.\n2. **My Plants Dashboard**: Track and manage your plant collection with photos, species information, and growth notes.\n3. **Automated Reminders**: Never forget watering or fertilization schedules with intelligent automated reminders.\n4. **Admin Analytics Dashboard**: Monitor user growth, popular plant trends, and content performance through visual charts (Pie, Bar, Line).\n\n**n8n Workflow Architecture:**\nThe core intelligence is powered by two specialized n8n workflows:\n- **Knowledge Base Powerhouse**: Processes raw documents (PDFs, docs) containing agricultural knowledge, splits them into chunks, generates vector embeddings, and stores them in Supabase Vector Store.\n- **AI Agent Brain**: Customer-facing conversational agent with contextual RAG, NLP, and response generation based on retrieved knowledge.\n\nThe application features a modern, responsive React UI with TypeScript, TailwindCSS, Radix UI components, and real-time data integration using TanStack Query.",
    "tech": [
      "React",
      "TypeScript",
      "Vite",
      "n8n",
      "Supabase",
      "TanStack Query",
      "TailwindCSS",
      "Radix UI",
      "RAG System",
      "Vector Embeddings",
      "Lucide React",
      "React Router DOM",
      "React Hook Form",
      "Zod",
      "Recharts",
      "Date-fns"
    ],
    "features": [
      "AI-Powered RAG Chatbot for Gardening Assistance",
      "n8n Workflow Orchestration (Knowledge Base + AI Agent)",
      "Supabase Vector Store for Document Embeddings",
      "My Plants Dashboard (Plant Collection Management)",
      "Automated Watering & Fertilization Reminders",
      "Admin Analytics Dashboard (Pie, Bar, Line Charts)",
      "Content Management System (Community Links, Videos)",
      "Product Recommendation Engine",
      "Responsive Modern UI with Dark Mode Support",
      "Real-time Data Fetching with TanStack Query",
      "Type-Safe Forms with React Hook Form & Zod",
      "Authentication & Authorization with Supabase Auth"
    ],
    "type": "AI Agent & RAG",
    "category": "nlp-genai",
    "link": "/projects/manggrow-id",
    "thumbnail": "/projects/manggrow-id/1.png",
    "demoLink": "https://manggrow.id",
    "githubLink": "https://github.com/yourusername/manggrow-id",
    "gallery": [
      "/projects/manggrow-id/1.png",
      "/projects/manggrow-id/2.png",
      "/projects/manggrow-id/3.png",
      "/projects/manggrow-id/4.png",
      "/projects/manggrow-id/5.png",
      "/projects/manggrow-id/6.png",
      "/projects/manggrow-id/7.png",
      "/projects/manggrow-id/8.png",
      "/projects/manggrow-id/9.png"
    ]
  },
  {
    "title": "Enterprise Asset Classification | Power Platform + AI",
    "description": "An end-to-end asset management solution for corporate environments. It combines Microsoft Power Apps for the user interface and Power Automate for approval workflows. The core intelligence is powered by n8n and LLMs to automatically classify asset categories based on descriptions, storing data securely in SharePoint.",
    "tech": [
      "Power Apps",
      "Power Automate",
      "SharePoint",
      "n8n",
      "LLM",
      "Microsoft 365"
    ],
    "type": "Business Automation",
    "category": "mlops-automation",
    "link": "/projects/asset-classification-powerapps",
    "thumbnail": "/projects/asset-classification-powerapps/powerapps.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/asset-classification-powerapps/powerapps.png"
    ]
  },
  {
    "title": "YOLOv11 & DeepSORT Speed Estimation | Real-Time Traffic Analytics",
    "description": "A high-performance computer vision application for analyzing traffic flow in real-time. Combines state-of-the-art YOLOv11 object detection with DeepSORT tracking to estimate vehicle speeds from video feeds. Built from scratch with custom PyTorch implementations of YOLOv11 architecture and DeepSORT tracking algorithms, demonstrating deep understanding of modern CV pipelines.",
    "longDescription": "**YOLOv11 & DeepSORT Speed Estimation** is a comprehensive traffic analysis platform that bridges the gap between research notebooks and production-ready applications.\n\nWhat makes this project unique is the **\"From Scratch\"** implementation approach. Instead of relying on opaque high-level libraries, the core logic for the **YOLOv11 Model Architecture** (C3K2, SPPF, PSA blocks) and **DeepSORT Tracker** has been extracted from research notebooks and re-engineered into a clean, modular Python codebase served via a modern web API.\n\n**The system features a dual-stage AI pipeline:**\n1. **Detection & Classification**: Custom PyTorch-based YOLOv11 implementation detects vehicles (cars, motorcycles, trucks) with high precision using advanced architectural components.\n2. **Tracking & Speed Estimation**: DeepSORT algorithm maintains persistent IDs across frames using Kalman Filters and Hungarian matching. Speed is calculated through pixel displacement analysis with perspective correction calibration.\n\n**Key capabilities include:**\n- **For Traffic Engineers**: Real-time speed monitoring, traffic flow analysis, automated violation detection, and comprehensive analytics dashboards.\n- **For Researchers**: Transparent, modular implementation showcasing how raw tensor manipulations translate to production pipelines.\n- **Video Processing**: Automatic FFmpeg transcoding ensures H.264/AAC encoding for seamless browser playback.\n\nThe application features a modern Next.js 14 UI with drag-and-drop video upload, real-time processing status updates via polling, and side-by-side comparison of original vs analyzed footage. The backend uses FastAPI for high-performance async video processing.",
    "tech": [
      "Python",
      "PyTorch",
      "FastAPI",
      "YOLOv11",
      "DeepSORT",
      "OpenCV",
      "NumPy",
      "FilterPy",
      "Scipy",
      "Kalman Filter",
      "Hungarian Algorithm",
      "FFmpeg",
      "Next.js",
      "React",
      "TypeScript",
      "TailwindCSS",
      "Docker",
      "Docker Compose",
      "Uvicorn"
    ],
    "features": [
      "Custom YOLOv11 Implementation from Scratch (C3K2, SPPF, PSA blocks)",
      "DeepSORT Multi-Object Tracking (Kalman + Hungarian Matching)",
      "Real-Time Speed Estimation with Perspective Correction",
      "Automatic Video Transcoding (H.264/AAC for Browser Playback)",
      "Drag & Drop Video Upload Interface",
      "Real-Time Processing Status Updates",
      "Side-by-Side Original vs Analyzed Video Comparison",
      "Modern Responsive UI with Next.js 14",
      "RESTful API with FastAPI",
      "Docker Containerization for Easy Deployment",
      "Modular, Production-Ready Codebase"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/vehicle-speed-estimation",
    "thumbnail": "/projects/vehicle-speed-estimation/1.png",
    "gallery": [
      "/projects/vehicle-speed-estimation/1.png",
      "/projects/vehicle-speed-estimation/2.png",
      "/projects/vehicle-speed-estimation/3.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/yolov11-deepsort-speed-estimation"
  },
  {
    "title": "InsightSphere | Enterprise Finance AI RAG System",
    "description": "An enterprise-grade financial analysis platform powered by RAG (Retrieval-Augmented Generation) technology. Enables financial analysts and consultants to instantly query complex documents (PDFs, Excel, Reports) and receive accurate, context-aware insights. The system supports multi-persona AI responses with ultra-fast inference powered by Groq and ChromaDB vector storage.",
    "longDescription": "**InsightSphere** is a comprehensive financial intelligence platform that transforms static financial reports into interactive knowledge bases through advanced RAG technology.\n\nThe system enables analysts to chat directly with uploaded documents, asking specific questions like \"What is the Q2 Year-over-Year growth?\" and receiving answers cited from the source. It implements a sophisticated multi-persona AI system, allowing users to switch between **Consultant**, **Neutral**, and **Casual** modes for tailored responses.\n\n**The platform features a dual-layer architecture:**\n1. **Ingestion Engine**: Documents are parsed (PDF, Docx, PPTX, Excel), split into semantic chunks, embedded using sentence-transformers, and stored in ChromaDB for O(1) retrieval.\n2. **RAG Inference Core**: User queries are embedded, top-k relevant chunks are retrieved from the vector store, and fed into Groq Llama-3 for ultra-fast, context-aware response generation.\n\n**Key capabilities include:**\n- **For Analysts**: Intelligent document chat with source citations, multi-format support (PDF, Excel, PPTX, Docx), persona-based AI responses, and automated report export to PowerPoint/Excel.\n- **For Administrators**: Real-time system health monitoring (LLM API, Vector Store, Backend), vector database management, pre-warm embeddings, document chunk oversight, and secure local deployment via Docker.\n\nThe application features a modern React + TypeScript UI powered by Vite, with TailwindCSS for styling and Lucide icons. The backend uses FastAPI for high-performance async API serving with LangChain orchestration.",
    "tech": [
      "Python",
      "FastAPI",
      "Groq API",
      "LlamaIndex",
      "LangChain",
      "ChromaDB",
      "FAISS",
      "Sentence Transformers",
      "PyPDF2",
      "Pandas",
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "Framer Motion",
      "Lucide Icons",
      "Docker",
      "Docker Compose",
      "Gunicorn",
      "Uvicorn"
    ],
    "features": [
      "Advanced RAG System with Groq Llama-3 (Ultra-Fast Inference)",
      "Multi-Format Document Ingestion (PDF, Excel, PPTX, Docx)",
      "Intelligent Semantic Chunking & Vector Storage (ChromaDB/FAISS)",
      "Multi-Persona AI Responses (Consultant/Neutral/Casual)",
      "Source-Cited Answers with Document References",
      "Automated Report Export (PowerPoint & Excel)",
      "Real-time System Health Monitoring Dashboard",
      "Vector Database Management & Pre-Warming",
      "Secure Local Deployment with Docker",
      "Responsive Modern UI with Dark Mode Support",
      "High-Performance Async API with FastAPI",
      "LangChain Orchestration for RAG Pipeline"
    ],
    "type": "GenAI & LLM",
    "category": "nlp-genai",
    "link": "/projects/finance-ai-agent",
    "thumbnail": "/projects/finance-ai-agent/1.png",
    "gallery": [
      "/projects/finance-ai-agent/1.png",
      "/projects/finance-ai-agent/2.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/enterprise-finance-ai"
  },
  {
    "title": "DERMA-DFU.ID | AI-Powered Diabetic Foot Ulcer Triage System",
    "description": "A comprehensive medical AI web application for intelligent screening and triage of diabetic foot ulcers. Leverages state-of-the-art deep learning models for infection detection, ischemia assessment, and automated wound measurement, providing evidence-based clinical decision support for rural healthcare workers and patients.",
    "longDescription": "**DERMA-DFU.ID** is an advanced healthcare platform designed to transform diabetic foot ulcer management through artificial intelligence. Built for resource-constrained settings, it empowers frontline healthcare workers and diabetes patients with instant, evidence-based triage capabilities.\n\nThe system performs multi-modal AI analysis combining **Classification** and **Segmentation**:\n1. **4-Class Deep Learning Classifier**: Detects None, Infection, Ischaemia, or Both conditions using a custom-trained EfficientNet-style CNN model.\n2. **U-Net Wound Segmentation**: Automatically measures wound area in pixels and converts to cm² using calibrated scale measurements.\n3. **Clinical Rule Engine**: Integrates AI predictions with critical clinical signs (fever, pulse, odor, pain) to generate safety-first triage decisions.\n\n**The Triage System (RED-YELLOW-GREEN)**:\n- **RED (≤48h Referral)**: Danger signs detected (fever, spreading redness, no pulse, severe kidney disease + infection) OR high ischaemia probability OR AI detects \"Both\" conditions.\n- **YELLOW (≤72h Tele-consult)**: Small wound with stable vitals OR mild infection/ischaemia detected by AI.\n- **GREEN (Self-care + Education)**: Pre-ulcer stage or minimal wound with no concerning features.\n\n**Key Technical Innovations**:\n- **100% Client-Side AI Inference**: All ML models run in-browser via ONNX Runtime WebAssembly—no patient data ever leaves the device, ensuring HIPAA-level privacy.\n- **Interactive Calibration System**: Two-point click measurement on ruler/card images for precise wound size calculation (mm/px scaling).\n- **Comprehensive Dashboard Analytics**: Performance indicators including time-to-referral, completion rates, photo adherence, and triage distribution.\n- **Tele-referral Integration**: Direct scheduling with specialists, real-time chat with doctors, and full digital health record management.\n\nThe application features a responsive React UI with dark mode, bilingual support (Indonesian/English), offline-capable PWA architecture, and Supabase backend with Row-Level Security for multi-tenant patient management.",
    "tech": [
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "shadcn/ui",
      "Radix UI",
      "ONNX Runtime Web",
      "Supabase",
      "PostgreSQL",
      "TanStack Query",
      "React Router DOM",
      "Deep Learning",
      "Computer Vision",
      "U-Net Segmentation",
      "EfficientNet",
      "TensorFlow (Model Training)",
      "Lucide Icons",
      "Sonner",
      "Zod"
    ],
    "features": [
      "AI-Powered 4-Class Infection/Ischaemia Detection",
      "Automated Wound Segmentation & Area Measurement (U-Net)",
      "Interactive Two-Point Calibration for Metric Scaling (mm/px)",
      "Evidence-Based RED-YELLOW-GREEN Triage System",
      "100% Client-Side Inference (Privacy-First, No Data Upload)",
      "Clinical Decision Support with Danger Sign Detection",
      "Real-Time Tele-Consultation Chat with Doctors",
      "Comprehensive Patient History & Analytics Dashboard",
      "Performance Metrics (Time-to-Referral, Completion Rates)",
      "Bilingual Interface (Indonesian/English)",
      "Responsive PWA with Offline Capability",
      "Role-Based Access Control (Patient/Admin/Doctor)",
      "Supabase Authentication & Row-Level Security (RLS)",
      "Photo Storage with Secure Public URLs",
      "CSV Export for Clinical Reporting",
      "Interactive Education Module (Guidelines, First Aid)",
      "Dark Mode Support"
    ],
    "type": "Healthcare AI",
    "category": "computer-vision",
    "link": "/projects/derma-dfu",
    "thumbnail": "/projects/derma-dfu/1.png",
    "demoLink": "https://derma-dfu.id",
    "githubLink": "https://github.com/rezayuridian-cell/derma-bantu-sehat",
    "gallery": [
      "/projects/derma-dfu/1.png",
      "/projects/derma-dfu/2.png",
      "/projects/derma-dfu/3.png",
      "/projects/derma-dfu/4.png",
      "/projects/derma-dfu/5.png",
      "/projects/derma-dfu/6.png",
      "/projects/derma-dfu/7.png",
      "/projects/derma-dfu/8.png"
    ]
  },
  {
    "title": "River Gauge AI | Intelligent Water Level Monitoring System",
    "description": "A production-grade computer vision system for automated hydrological monitoring. Leverages YOLOv8 object detection to identify and read water gauge markings from RTSP video streams or uploaded footage. Features intelligent waterline detection using texture analysis and robust tick fitting algorithms, with real-time alerting for critical water levels.",
    "longDescription": "**River Gauge AI** is an enterprise-ready platform designed to automate the monitoring of water levels in rivers, dams, and reservoirs. It eliminates the need for manual gauge readings by providing 24/7 automated detection with visual verification.\n\nThe system processes video feeds (RTSP streams or uploaded files) and uses advanced computer vision to detect staff gauges, identify percentage tick marks, and measure the exact water surface level. Each reading is calibrated to real-world elevation values and compared against configurable Yellow/Red alert thresholds.\n\n**The AI pipeline consists of four stages:**\n1. **Object Detection**: YOLOv8 model trained to detect percentage ticks (0%, 10%, 20%...100%) and staff gauge boards\n2. **ROI Extraction**: Automatically crops the region of interest around detected gauges with smart padding\n3. **Waterline Detection**: Multi-algorithm approach combining texture energy analysis, gradient detection, and side-aware processing to identify the water surface\n4. **Elevation Calculation**: Robust linear regression fitting with rate-limiting to prevent false spikes\n\n**Key capabilities include:**\n- **For Operators**: Real-time monitoring dashboard with live video feeds, configurable alert zones (Yellow/Red), and visual overlays showing detected ticks and water levels\n- **For Analysts**: Historical data visualization with Chart.js, exportable reports, and video playback with synchronized data\n- **For Engineers**: Multi-project management, custom calibration parameters (base elevation low/high), and RTSP stream integration\n\nThe application features a modern React dashboard with TypeScript, supporting multiple concurrent monitoring sites. The backend uses FastAPI with async processing, SQLAlchemy for persistence, and FFmpeg for video handling. The CV engine leverages OpenCV with optional OpenCL acceleration and supports both CPU and GPU (CUDA) inference.\n\n**Advanced Features:**\n- Rate-limiting algorithm to filter false readings (max cm/sec threshold)\n- Smart ROI zoom with texture-aware waterline detection\n- Hold-last-known-good fallback for temporary detection failures\n- Alert level visualization with color-coded overlays (Green/Yellow/Red zones)\n- Docker containerization with docker-compose orchestration",
    "tech": [
      "Python",
      "FastAPI",
      "Uvicorn",
      "YOLOv8",
      "Ultralytics",
      "OpenCV",
      "NumPy",
      "PyTorch",
      "SQLAlchemy",
      "SQLite",
      "FFmpeg",
      "Pandas",
      "React",
      "TypeScript",
      "Vite",
      "Vanilla CSS",
      "Chart.js",
      "React Router DOM",
      "Lucide Icons",
      "Docker",
      "Docker Compose",
      "CUDA"
    ],
    "features": [
      "YOLOv8-Based Gauge Detection (Tick Mark Recognition)",
      "Intelligent Waterline Detection (Texture + Gradient Analysis)",
      "Real-time RTSP Stream Processing",
      "Multi-Project Dashboard (Manage Multiple Monitoring Sites)",
      "Configurable Alert System (Yellow/Red Thresholds)",
      "Historical Data Visualization (Chart.js Trends)",
      "Rate-Limiting Algorithm (Prevent False Spikes)",
      "ROI Auto-Cropping with Smart Padding",
      "Video Playback with Synchronized Data",
      "Visual Overlays (Detection Boxes, Water Level Lines)",
      "Elevation Calibration (Base Low/High Configuration)",
      "Hold-Last-Known-Good Fallback Logic",
      "Responsive Modern UI with Dark Theme",
      "GPU/CUDA Support with CPU Fallback",
      "Docker Containerization",
      "FFmpeg Video Processing Integration"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/water-scale-monitor",
    "thumbnail": "/projects/water-scale-monitor/1.png",
    "gallery": [
      "/projects/water-scale-monitor/1.png",
      "/projects/water-scale-monitor/2.png",
      "/projects/water-scale-monitor/3.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/river-gauge-vision"
  },
  {
    "title": "Product Demand Forecasting | LSTM Time Series Prediction",
    "description": "An advanced time series forecasting project that predicts weekly product demand across multiple sites using deep learning. The model employs LSTM neural networks built with TensorFlow/Keras to analyze historical sales data and generate accurate demand predictions for inventory optimization.",
    "longDescription": "**Product Demand Forecasting** is a comprehensive machine learning solution designed to predict future product sales using time series analysis.\n\nThe system processes transactional data from 2,065 unique products across 5 different sites, spanning from August 2024 to July 2025 (approximately 11,917 transaction records). It transforms daily sales data into weekly aggregated forecasts to help businesses optimize inventory management and reduce stockouts.\n\n**Technical Implementation:**\n1. **Data Preprocessing**: Weekly aggregation, series filtering, outlier capping, log transformation, and standard scaling\n2. **LSTM Architecture**: Global LSTM model with regularization techniques to prevent overfitting\n3. **Training**: Custom callbacks including EarlyStopping and ReduceLROnPlateau for optimal convergence\n4. **Evaluation**: Comprehensive metrics including RMSE, MAE, and integer-rounded predictions for practical business use\n5. **Inference**: Production-ready inference pipeline for single product-site predictions\n\n**Key capabilities include:**\n- Multi-site, multi-product demand forecasting\n- Handling of sparse and irregular time series data\n- Robust preprocessing pipeline (capping, log transform, scaling)\n- Weekly demand prediction with integer output for actionable insights\n- Model persistence for deployment and batch inference\n- Statistical analysis and visualization of demand patterns\n\nThe project uses LightGBM for feature engineering and TensorFlow for deep learning, delivering production-grade forecasts that support strategic business decisions.",
    "tech": [
      "Python",
      "TensorFlow",
      "Keras",
      "LSTM",
      "Pandas",
      "NumPy",
      "Matplotlib",
      "Seaborn",
      "Scikit-learn",
      "LightGBM",
      "StandardScaler",
      "Time Series Analysis",
      "Deep Learning",
      "Jupyter Notebook",
      "Openpyxl"
    ],
    "features": [
      "Multi-Product Multi-Site Demand Forecasting",
      "LSTM-Based Time Series Prediction",
      "Weekly Aggregated Forecast Output",
      "Robust Data Preprocessing Pipeline (Capping, Log, Scaling)",
      "Custom Training Callbacks (EarlyStopping, ReduceLROnPlateau)",
      "Integer-Rounded Predictions for Business Use",
      "Model Persistence & Batch Inference",
      "Comprehensive EDA & Statistical Analysis",
      "Handles 2,065 Products Across 5 Sites",
      "Production-Ready Inference Pipeline"
    ],
    "type": "Time Series Forecasting",
    "category": "data-science",
    "link": "/projects/demand-forecasting-lstm",
    "thumbnail": "/projects/demand-forecasting-lstm/1.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/demand-forecasting-lstm/1.png",
      "/projects/demand-forecasting-lstm/2.png",
      "/projects/demand-forecasting-lstm/3.png",
      "/projects/demand-forecasting-lstm/4.png",
      "/projects/demand-forecasting-lstm/5.png",
      "/projects/demand-forecasting-lstm/6.png",
      "/projects/demand-forecasting-lstm/7.png"
    ]
  },
  {
    "title": "End-to-End MLOps Workflow",
    "description": "A demonstration of a complete Machine Learning Operations (MLOps) pipeline. It integrates MLflow for experiment tracking, DagsHub for collaboration, Docker for containerization, and Grafana/Prometheus for system monitoring.",
    "tech": [
      "MLflow",
      "Docker",
      "Grafana",
      "Prometheus",
      "DagsHub",
      "CI/CD"
    ],
    "type": "MLOps",
    "category": "mlops-automation",
    "link": "/projects/mlops-workflow",
    "thumbnail": "/projects/mlops-workflow/mlflow.png",
    "demoLink": "#",
    "githubLink": "https://github.com/yourusername/mlops-pipeline",
    "gallery": [
      "/projects/mlops-workflow/mlflow.png"
    ]
  },
  {
    "title": "Customer Segmentation using RFM Analysis | K-Means Clustering for Retail Marketing",
    "description": "An advanced customer segmentation project utilizing RFM (Recency, Frequency, Monetary) analysis combined with K-Means clustering to identify distinct customer groups for targeted retail marketing strategies. Built entirely with Python, Pandas, and Scikit-learn, this analysis processes over 1M transactions to segment 5,000+ customers into actionable marketing personas.",
    "longDescription": "This comprehensive data science project demonstrates end-to-end customer segmentation using RFM analysis, a powerful technique in retail analytics for understanding customer behavior and value.\n\n**The system implements a complete analytical pipeline:**\n1. **Data Cleaning & Preprocessing**: Handles 1M+ transaction records, removes anomalies, filters out negative quantities and prices, and validates customer data\n2. **RFM Feature Engineering**: Constructs Recency (days since last purchase), Frequency (total transactions), and Monetary (total spending) metrics for each customer\n3. **Outlier Detection**: Applies IQR (Interquartile Range) method to remove statistical outliers and ensure robust clustering\n4. **Log Transformation**: Normalizes skewed Frequency and Monetary distributions for better clustering performance\n5. **K-Means Clustering**: Uses elbow method and silhouette analysis to determine optimal number of customer segments\n6. **Customer Profiling**: Creates actionable marketing personas based on cluster characteristics\n\n**Key Insights Generated:**\n- Identifies high-value customers (Champions) for VIP treatment and loyalty programs\n- Detects at-risk customers (Need Attention) for retention campaigns\n- Segments new customers for onboarding strategies\n- Finds dormant customers for re-engagement campaigns\n\nThe analysis reduces the customer base from 5,878 to 5,001 customers after outlier removal, with clustering performed on standardized RFM features. All visualizations use Matplotlib and Seaborn for professional data presentation.",
    "tech": [
      "Python",
      "Pandas",
      "NumPy",
      "Scikit-learn",
      "K-Means Clustering",
      "StandardScaler",
      "Matplotlib",
      "Seaborn",
      "Google Colab",
      "Yellowbrick"
    ],
    "features": [
      "Comprehensive Data Cleaning (1M+ transactions processed)",
      "RFM Metric Calculation (Recency, Frequency, Monetary)",
      "IQR-based Outlier Detection and Removal",
      "Log Transformation for Feature Engineering",
      "K-Means Clustering with Elbow Method Optimization",
      "Silhouette Score Analysis for Cluster Validation",
      "Multiple Clustering Algorithm Comparison (K-Means, Agglomerative, DBSCAN, GMM)",
      "Customer Segment Profiling and Interpretation",
      "Statistical Distribution Visualization",
      "Standardized Feature Scaling"
    ],
    "type": "Data Science",
    "category": "data-science",
    "link": "/projects/rfm-customer-segmentation",
    "thumbnail": "/projects/rfm-customer-segmentation/1.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/rfm-customer-segmentation/1.png",
      "/projects/rfm-customer-segmentation/2.png",
      "/projects/rfm-customer-segmentation/3.png",
      "/projects/rfm-customer-segmentation/4.png",
      "/projects/rfm-customer-segmentation/5.png",
      "/projects/rfm-customer-segmentation/6.png",
      "/projects/rfm-customer-segmentation/7.png",
      "/projects/rfm-customer-segmentation/8.png",
      "/projects/rfm-customer-segmentation/9.png",
      "/projects/rfm-customer-segmentation/10.png",
      "/projects/rfm-customer-segmentation/11.png"
    ]
  },
  {
    "title": "Face Recognition Attendance System | Anti-Spoofing Security",
    "description": "An enterprise-grade automated attendance platform designed for universities and corporations. Leverages AI-powered face recognition with advanced anti-spoofing technology to provide secure, contactless, and instant verification. The system combines YOLOv11 for face detection and InsightFace for recognition, featuring active liveness detection to prevent photo and video replay attacks.",
    "longDescription": "**Face Recognition Attendance System** is a comprehensive platform that modernizes classroom and organizational attendance through state-of-the-art AI technology.\n\nAt its core is a powerful **Anti-Spoofing Engine** that analyzes texture patterns (LBP), motion, color distribution, and moire artifacts to differentiate real faces from photos or digital screens. This ensures the highest integrity of attendance records.\n\n**The system features a dual-stage AI pipeline:**\n1. **Detection & Liveness Verification**: YOLOv11-Face detects faces and custom CV algorithms verify liveness through micro-movement analysis (blinking, breathing) and texture analysis before processing.\n2. **Face Recognition**: InsightFace (ArcFace) extracts 512-dimensional vector embeddings and matches them against the database using cosine similarity for high-confidence identification.\n\n**Key capabilities include:**\n- **For Lecturers**: Live attendance feed with real-time visual feedback, class scheduling, student enrollment management, and automated attendance reports.\n- **For Administrators**: Centralized user management, system analytics, performance monitoring, and secure biometric data management.\n- **Security Features**: Multi-layer anti-spoofing (texture, motion, depth analysis), encrypted face embeddings, and audit logging.\n\nThe application features a modern, responsive React UI with premium design, real-time WebSocket updates, and comprehensive admin dashboards. The backend uses Flask with SQLAlchemy for robust data persistence.",
    "tech": [
      "Python",
      "Flask",
      "React",
      "Vite",
      "TailwindCSS",
      "YOLOv11",
      "InsightFace",
      "ArcFace",
      "TensorFlow",
      "OpenCV",
      "NumPy",
      "PyTorch",
      "SQLAlchemy",
      "Socket.IO",
      "MySQL",
      "Docker",
      "Gunicorn"
    ],
    "features": [
      "Advanced Anti-Spoofing Detection (Texture, Motion, Depth Analysis)",
      "Active Liveness Detection (Blink & Micro-Movement)",
      "Real-time Face Recognition with InsightFace (512D Embeddings)",
      "Live Attendance Feed with WebSocket Updates",
      "Class & Student Management Dashboard",
      "Automated Attendance Reports & Export (Excel)",
      "Admin Panel (User, Class, Subject Management)",
      "Secure Face Enrollment & Biometric Storage",
      "System Analytics & Performance Monitoring",
      "Responsive Modern UI with Dark Mode Support",
      "Docker Containerization for Easy Deployment"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/face-recognition-attendance",
    "thumbnail": "/projects/face-recognition-attendance/1.png",
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/face-recognition-attendance-app",
    "gallery": [
      "/projects/face-recognition-attendance/1.png",
      "/projects/face-recognition-attendance/2.png",
      "/projects/face-recognition-attendance/3.png",
      "/projects/face-recognition-attendance/4.png",
      "/projects/face-recognition-attendance/5.png",
      "/projects/face-recognition-attendance/6.png",
      "/projects/face-recognition-attendance/7.png",
      "/projects/face-recognition-attendance/8.png",
      "/projects/face-recognition-attendance/9.png"
    ]
  },
  {
    "title": "Static QnA Chatbot",
    "description": "An NLP-based chatbot that answers user questions from a predefined QnA document. It uses text preprocessing, TF-IDF, and cosine similarity to retrieve the most relevant answers. The frontend is built with ReactJS + TailwindCSS and the backend uses NodeJS.",
    "tech": [
      "TensorFlow",
      "ReactJS",
      "TailwindCSS",
      "NodeJS",
      "Cosine Similarity",
      "NLP"
    ],
    "type": "NLP",
    "category": "nlp-genai",
    "link": "/projects/qna-chatbot-static",
    "thumbnail": "/projects/qna-chatbot-static/qna.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/qna-chatbot-static/qna.png"
    ]
  },
  {
    "title": "Chat With Your Documents | RAG System",
    "description": "A Retrieval-Augmented Generation (RAG) application that allows users to upload documents and chat with their content. It uses LangChain, Pinecone, and Groq LLaMA API for semantic retrieval, with a Streamlit UI and FastAPI backend.",
    "tech": [
      "LangChain",
      "Pinecone",
      "Groq API",
      "LLaMA",
      "FastAPI",
      "Streamlit"
    ],
    "type": "RAG System",
    "category": "nlp-genai",
    "link": "/projects/chat-with-documents",
    "thumbnail": "/projects/chat-with-documents/cwyd.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/chat-with-documents/cwyd.png"
    ]
  },
  {
    "title": "Nail Virtual Try-On | AI-Powered Beauty Tech Platform",
    "description": "An enterprise-grade virtual try-on platform for nail polish powered by advanced AI segmentation. Enables users to instantly preview thousands of nail polish colors and finishes on their own hands through real-time computer vision and WebGL rendering. Features 95%+ accuracy nail detection using TensorFlow.js and MediaPipe Hands, with complete client-side processing for maximum privacy.",
    "longDescription": "**Nail Virtual Try-On** is a cutting-edge beauty tech platform that revolutionizes the nail polish shopping experience through artificial intelligence. Built for cosmetics brands and beauty enthusiasts, it eliminates the guesswork of online nail polish shopping by providing photorealistic virtual try-on experiences.\n\nThe platform solves the fundamental problem of \"How will this color look on my nails?\" by combining state-of-the-art computer vision with stunning WebGL rendering to deliver instant, realistic previews.\n\n**The system features a dual-layer AI architecture:**\n1. **Client-Side AI Engine**: TensorFlow.js-powered nail segmentation with 95%+ accuracy, running entirely in the browser for zero-latency results and complete privacy protection.\n2. **Server-Side Processing**: FastAPI backend with TensorFlow Lite models for high-precision segmentation, batch processing, and advanced color correction algorithms.\n\n**Key capabilities include:**\n- **For Consumers**: Access to 10,000+ nail polish shades with realistic effects (glossy, matte, metallic, pearl), instant try-on without app downloads, and side-by-side comparison of multiple colors.\n- **For Brands**: Reduced product returns, increased conversion rates, comprehensive analytics on color popularity, and seamless integration into existing e-commerce platforms.\n- **For Developers**: RESTful API with full OpenAPI documentation, modular architecture for easy customization, and Docker deployment for scalability.\n\n**Advanced Features:**\n- **Hand Tracking**: MediaPipe Hands integration for real-time finger detection and landmark tracking\n- **3D Rendering**: React Three Fiber and Three.js for photorealistic lighting and material rendering\n- **Smart Color Matching**: AI-powered color correction based on skin tone detection\n- **Multi-Format Support**: Works with uploaded images and live webcam feeds\n- **Social Sharing**: Export high-resolution images optimized for Instagram/TikTok\n\nThe application features a stunning Next.js 14 UI with TypeScript, shadcn/ui components, Framer Motion animations, and state management via Zustand. The backend leverages FastAPI with async processing, ONNX Runtime for optimized inference, and comprehensive logging via Loguru.\n\n**Privacy-First Architecture:**\nAll AI processing happens locally in the browser by default. No images are sent to servers unless explicitly requested by the user for high-precision processing. This ensures GDPR compliance and maximum user trust.",
    "tech": [
      "Next.js",
      "React",
      "TypeScript",
      "FastAPI",
      "Python",
      "TensorFlow.js",
      "TensorFlow Lite",
      "ONNX Runtime",
      "MediaPipe Hands",
      "OpenCV",
      "TailwindCSS",
      "shadcn/ui",
      "Radix UI",
      "Three.js",
      "React Three Fiber",
      "Framer Motion",
      "WebGL",
      "Zustand",
      "Axios",
      "NumPy",
      "Pillow",
      "scikit-image",
      "Redis",
      "Docker",
      "Docker Compose",
      "Loguru"
    ],
    "features": [
      "Real-time AI Nail Segmentation (95%+ Accuracy)",
      "10,000+ Nail Polish Colors & Shades",
      "Realistic Finish Effects (Glossy, Matte, Metallic, Pearl)",
      "Client-Side AI Processing (Privacy-First, Zero Server Upload)",
      "MediaPipe Hand Tracking & Landmark Detection",
      "WebGL 3D Rendering with Realistic Lighting",
      "Live Webcam & Image Upload Support",
      "Smart Color Correction Based on Skin Tone",
      "Side-by-Side Color Comparison",
      "High-Resolution Export for Social Media",
      "RESTful API with OpenAPI Documentation",
      "Responsive Modern UI with Dark Mode Support",
      "Lightning-Fast Inference (<1 Second)",
      "Batch Processing for Multiple Images",
      "Docker Containerization for Easy Deployment",
      "CI/CD Pipeline with GitHub Actions",
      "Redis Caching for Performance Optimization",
      "Comprehensive Logging & Error Tracking"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/virtual-tryon-nail",
    "thumbnail": "/projects/virtual-tryon-nail/1.png",
    "demoLink": "https://virtual-tryon-nail.vercel.app",
    "githubLink": "https://github.com/ferrikrisdiantoro/virtual-tryon-nail",
    "gallery": [
      "/projects/virtual-tryon-nail/1.png",
      "/projects/virtual-tryon-nail/2.png",
      "/projects/virtual-tryon-nail/3.png",
      "/projects/virtual-tryon-nail/4.png",
      "/projects/virtual-tryon-nail/5.png"
    ]
  },
  {
    "title": "Waste Classification | Organic vs Recycle",
    "description": "An image classification project that classifies waste into Organic or Recycle categories. The model is built using TensorFlow and Keras, while Streamlit is used to display predictions and probability charts.",
    "tech": [
      "TensorFlow",
      "Keras",
      "Streamlit",
      "Image Classification"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/waste-classification",
    "thumbnail": "/projects/waste-classification/waste.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/waste-classification/waste.png"
    ]
  },
  {
    "title": "Playstore App Comment Sentiment Analysis",
    "description": "A text classification model for categorizing Playstore app reviews into Positive, Negative, and Neutral sentiments. The project is developed in Google Colab using TensorFlow and an LSTM-based architecture.",
    "tech": [
      "TensorFlow",
      "Keras",
      "LSTM",
      "NLP",
      "Colab"
    ],
    "type": "NLP",
    "category": "nlp-genai",
    "link": "/projects/playstore-sentiment",
    "thumbnail": "/projects/playstore-sentiment/sentiment.png",
    "demoLink": "#",
    "githubLink": "#",
    "gallery": [
      "/projects/playstore-sentiment/sentiment.png"
    ]
  },
  {
    "title": "WEB.DERMA-DFU.ID | Healthcare E-Commerce & Partner Platform",
    "description": "A comprehensive healthcare e-commerce platform for diabetic wound care products in Indonesia. Features multi-language support, product marketplace with shopping cart, partner registration system, educational hub, and AI-powered chatbot for customer service using n8n RAG automation.",
    "longDescription": "**WE.DERMA-DFU.ID** is a full-stack healthcare e-commerce platform designed to connect patients with diabetic wound care products and healthcare partners across Indonesia.\n\nThe platform features an **intelligent customer service chatbot** powered by RAG (Retrieval-Augmented Generation) orchestrated through n8n workflows, providing instant answers to wound care questions based on a curated medical knowledge base.\n\n**Key capabilities include:**\n1. **Product Marketplace**: Curated catalog of advanced wound care products (hydrocolloid dressings, monitoring systems) with complete e-commerce functionality\n2. **Multi-Language Support**: Seamless switching between Indonesian and English for broader accessibility\n3. **Partner Portal**: Dedicated system for healthcare providers and distributors to register and manage their offerings\n4. **Educational Hub**: Comprehensive medical resources, articles, and webinar promotions for patient education\n5. **AI Customer Service**: n8n-powered RAG chatbot for automated, accurate medical product inquiries\n6. **User Dashboard**: Order tracking, consultation history, and personalized content management\n7. **Admin Panel**: Complete platform management including users, content, and analytics\n\nThe application is built with a modern React + TypeScript frontend using shadcn-ui component library, secured with Supabase authentication and PostgreSQL database, and features premium responsive design with dark mode support.",
    "tech": [
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "shadcn-ui",
      "Supabase",
      "PostgreSQL",
      "n8n",
      "RAG System",
      "React Query",
      "React Router DOM",
      "React Hook Form",
      "Zod",
      "Lucide Icons",
      "Recharts"
    ],
    "features": [
      "AI-Powered Customer Service Chatbot (n8n RAG)",
      "E-Commerce Platform with Shopping Cart & Checkout",
      "Multi-Language Support (Indonesian/English)",
      "User Authentication & Role-Based Access Control",
      "Partner Registration & Management System",
      "Educational Content Hub & Webinar Promotions",
      "User Dashboard with Order & Consultation Tracking",
      "Admin Panel (Product, User & Content Management)",
      "Responsive Modern UI with Dark Mode Support",
      "Real-time Data Syncing with React Query",
      "Form Validation with Zod & React Hook Form",
      "Supabase Backend Integration"
    ],
    "type": "E-Commerce Platform",
    "category": "web-application",
    "link": "/projects/web.derma-dfu",
    "thumbnail": "/projects/web.derma-dfu/1.png",
    "demoLink": "https://web.derma-dfu.id",
    "githubLink": "#",
    "gallery": [
      "/projects/web.derma-dfu/1.png",
      "/projects/web.derma-dfu/2.png",
      "/projects/web.derma-dfu/3.png",
      "/projects/web.derma-dfu/4.png",
      "/projects/web.derma-dfu/5.png",
      "/projects/web.derma-dfu/6.png",
      "/projects/web.derma-dfu/7.png",
      "/projects/web.derma-dfu/8.png",
      "/projects/web.derma-dfu/9.png",
      "/projects/web.derma-dfu/10.png",
      "/projects/web.derma-dfu/11.png"
    ]
  },
  {
    "title": "Multimodal Emotion Classification | Building and Comparing Unimodal vs Multimodal Approach",
    "description": "A comprehensive deep learning project comparing the performance of unimodal (text-only, image-only) versus multimodal (text + image) models for emotion classification. Features advanced techniques including OCR fusion, feature gating, and contrastive learning to classify 7 emotion categories with high accuracy.",
    "longDescription": "**Multimodal Emotion Classification** is an advanced machine learning system that explores the effectiveness of combining multiple modalities (text and images) for emotion detection compared to single-modality approaches.\n\nThe system classifies content into **7 emotion categories**: Anger, Fear, Happiness, Hate, Love, Sorrow, and Surprise, using a sophisticated hybrid architecture.\n\n**Key capabilities include:**\n\n1. **Unimodal Models**:\n   - **Text-Only**: RoBERTa-large based classifier with text masking and label smoothing (F1: 91.21%)\n   - **Image-Only**: ResNet50 with ImageNet pre-training and data augmentation (F1: 87.07%)\n\n2. **Multimodal Fusion**:\n   - Late fusion with learnable gating mechanism\n   - Feature-level alignment using contrastive loss (InfoNCE)\n   - Modality dropout for robustness (20% for both text and image)\n   - Achieves superior performance (F1: 92.30%) by leveraging complementary information\n\n3. **Advanced Techniques**:\n   - **OCR Integration**: Tesseract-based text extraction from images, fused with caption text\n   - **Cross-Modal Alignment**: Contrastive learning to align text and image representations\n   - **Class Imbalance Handling**: Weighted sampling + Class-Balanced Focal Loss\n   - **Stratified Group K-Fold**: Prevents data leakage from duplicate/similar captions\n\n4. **Training Optimizations**:\n   - Partial unfreezing (RoBERTa last 6 layers, ResNet layer3/layer4)\n   - Differential learning rates (2e-5 for backbone, 6e-5 for heads)\n   - Gradient clipping and AMP for stable training\n   - Cosine annealing LR schedule with warmup\n\nThe project demonstrates that multimodal models outperform unimodal counterparts by 1-5% F1 score, validating the benefit of cross-modal learning for emotion recognition tasks.",
    "tech": [
      "Python",
      "PyTorch",
      "Transformers",
      "RoBERTa-large",
      "ResNet50",
      "Tesseract OCR",
      "TensorFlow",
      "Keras",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "Matplotlib",
      "Seaborn",
      "Google Colab",
      "CUDA"
    ],
    "features": [
      "7-Class Emotion Classification (Anger, Fear, Happiness, Hate, Love, Sorrow, Surprise)",
      "Unimodal Text Classifier (RoBERTa-large, F1: 91.21%)",
      "Unimodal Image Classifier (ResNet50, F1: 87.07%)",
      "Multimodal Fusion Model with Feature Gating (F1: 92.30%)",
      "OCR-Enhanced Text Processing (Tesseract + Caption Fusion)",
      "Cross-Modal Contrastive Learning (InfoNCE Loss)",
      "Class-Balanced Focal Loss for Imbalanced Data",
      "Stratified Group K-Fold Cross-Validation (Prevents Data Leakage)",
      "Modality Dropout for Robustness (20% Text/Image)",
      "Partial Model Unfreezing (Transfer Learning)",
      "Comprehensive Evaluation (Accuracy, Precision, Recall, F1, Confusion Matrix)",
      "Performance Comparison Dashboard (Unimodal vs Multimodal)"
    ],
    "type": "Multimodal Learning",
    "category": "nlp-genai",
    "link": "/projects/multimodal-emotion-classification",
    "thumbnail": "/projects/multimodal-emotion-classification/1.png",
    "gallery": [
      "/projects/multimodal-emotion-classification/1.png",
      "/projects/multimodal-emotion-classification/2.png",
      "/projects/multimodal-emotion-classification/3.png",
      "/projects/multimodal-emotion-classification/4.png",
      "/projects/multimodal-emotion-classification/5.png",
      "/projects/multimodal-emotion-classification/6.png",
      "/projects/multimodal-emotion-classification/7.png",
      "/projects/multimodal-emotion-classification/8.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/multimodal-emotion-classification"
  },
  {
    "title": "Concrete Defect Detection | Enterprise Structural Health Monitoring",
    "description": "An enterprise-grade AI platform for automated civil infrastructure inspection. Leverages advanced Computer Vision to detect, classify, and assess the severity of 5 types of structural defects in concrete columns. Designed for civil engineers and inspectors to transform manual visual inspections into digital, auditable, and quantifiable workflows.",
    "longDescription": "**Concrete Defect Detection** is a comprehensive structural health monitoring system built for the construction and civil engineering industries. It automates the inspection process for concrete infrastructure, providing rapid and accurate defect analysis.\n\nThe platform identifies **5 critical damage types**: Crack, Spalling, Honeycomb, Segregation, and Corrosion. Each detection is automatically classified by severity (Minor, Moderate, Severe) based on damage area ratios and visual characteristics.\n\n**Key capabilities include:**\n1. **Multi-Class Detection**: High-precision YOLO/CNN model optimized with ONNX Runtime for CPU inference\n2. **Severity Assessment**: Intelligent severity grading using area analysis and damage-specific thresholds\n3. **Smart Recommendations**: ISO/ACI-compliant repair solutions based on damage type and severity\n4. **BIM Integration**: Exports IFC Overlay JSON for seamless integration with Autodesk Revit/Dynamo\n5. **History & Analytics**: Tracks defect progression over time with filtering and analytics dashboard\n\nThe system features a fully responsive React UI with stunning visual design, dark mode, and interactive data cards powered by Framer Motion. The backend uses FastAPI for high-performance async inference.",
    "tech": [
      "Python",
      "FastAPI",
      "ONNX Runtime",
      "Computer Vision",
      "YOLO",
      "OpenCV",
      "NumPy",
      "Pillow",
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "Framer Motion"
    ],
    "features": [
      "Multi-Class Defect Detection (5 Damage Types)",
      "Intelligent Severity Grading (Minor/Moderate/Severe)",
      "ISO/ACI-Standard Repair Recommendations",
      "BIM Integration (IFC Overlay Export for Revit)",
      "Defect History & Analytics Dashboard",
      "Responsive Modern UI with Dark Mode",
      "High-Performance CPU Inference with ONNX",
      "JSON-Based Storage (Scalable to PostgreSQL)"
    ],
    "type": "Computer Vision",
    "category": "computer-vision",
    "link": "/projects/concrete-defect-detection",
    "thumbnail": "/projects/concrete-defect-detection/1.png",
    "gallery": [
      "/projects/concrete-defect-detection/1.png",
      "/projects/concrete-defect-detection/2.png",
      "/projects/concrete-defect-detection/3.png",
      "/projects/concrete-defect-detection/4.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/concrete-defect-detection"
  },
  {
    "title": "StockAI - IDX Prediction Platform | AI-Powered Stock Market Analysis",
    "description": "An enterprise-grade financial analytics platform for predicting stock movements on the Indonesia Stock Exchange (IDX). Combines Machine Learning with Bandar Analysis (Broker Accumulation) to identify high-probability trading signals. Designed for traders and analysts to transform raw stock data into actionable insights through a modern, responsive dashboard.",
    "longDescription": "**StockAI** is a comprehensive stock market intelligence system built for the Indonesian financial market. It automates the analysis of daily market snapshots, broker activities, and technical indicators to generate actionable trading signals.\n\nThe platform processes daily market data and analyzes broker accumulation patterns (\"Bandarology\") to detect smart money movements. Each stock is assigned a Machine Learning probability score indicating the likelihood of price increases, combined with automated explanation generation.\n\n**Key capabilities include:**\n1. **Smart Signal Detection**: Automatically identifies stocks with BUY or STRONG SELL signals based on ML probability and technical indicators\n2. **Bandar Accumulation Analysis**: Visualizes top buyer concentration to detect institutional money movements\n3. **ML Probability Scoring**: XGBoost/Sklearn-powered inference engine assigns `prob_up` scores to every stock\n4. **Backtesting Engine**: Verify strategy performance against historical data with customizable date ranges\n5. **Real-time Filtering**: Filter opportunities by Threshold %, Broker, Price Range, and Signal Type\n6. **Automated Explanations**: Human-readable reasons for every signal (e.g., \"Volume sangat padat\", \"Ada dominasi Broker X\")\n\nThe system features a fully responsive React UI with modern design, dark mode support, and real-time data tables. The backend uses FastAPI for high-performance async API serving with NaN/Inf-safe JSON responses.",
    "tech": [
      "Python",
      "FastAPI",
      "Uvicorn",
      "Pandas",
      "NumPy",
      "Scikit-learn",
      "XGBoost",
      "Joblib",
      "React",
      "TypeScript",
      "Vite",
      "TailwindCSS",
      "React Router DOM",
      "Lucide Icons",
      "Docker",
      "GitHub Actions"
    ],
    "features": [
      "ML-Powered Stock Movement Prediction (XGBoost)",
      "Broker Accumulation Analysis (Bandarology)",
      "Smart Signal Detection (BUY/STRONG SELL)",
      "Probability Scoring for Every Stock (prob_up)",
      "Backtesting Engine with Historical Data",
      "Real-time Filtering (Threshold, Broker, Price Range)",
      "Automated Signal Explanations",
      "Responsive Modern UI with Dark Mode",
      "High-Performance FastAPI Backend",
      "NaN/Inf-Safe JSON Responses",
      "CI/CD Pipeline with GitHub Actions",
      "Docker & Docker Compose Support"
    ],
    "type": "Machine Learning",
    "category": "data-science",
    "link": "/projects/stockai-idx-prediction",
    "thumbnail": "/projects/stockai-idx-prediction/1.png",
    "gallery": [
      "/projects/stockai-idx-prediction/1.png",
      "/projects/stockai-idx-prediction/2.png"
    ],
    "demoLink": "#",
    "githubLink": "https://github.com/ferrikrisdiantoro/idx-smallcap-screener"
  },
  {
    "title": "cGAN & VGG16 for Scalp Disorder Classification",
    "description": "A multi-class image classification system combining Conditional GAN for synthetic data generation and VGG16-style architecture for medical image classification of scalp disorders. Built from scratch using TensorFlow/Keras and PyTorch for data augmentation through generative modeling.",
    "longDescription": "This project tackles the challenge of medical image classification for scalp disorders using a two-stage deep learning pipeline:\n\n**1. Synthetic Data Generation (cGAN):**\n- Developed a Conditional GAN using PyTorch to address class imbalance\n- Generates synthetic scalp disorder images conditioned on 12 different classes\n- Produces 200 synthetic images per class for data augmentation\n- Uses 64x64 image resolution with 100-dimensional latent space\n- Trained for 50 epochs using Adam optimizer with custom learning rates\n\n**2. Classification Model (VGG16):**\n- Custom VGG16-style CNN architecture built with TensorFlow/Keras\n- Multi-class classification across 12 scalp disorder categories\n- Input resolution: 224x224 RGB images\n- Includes data augmentation pipeline using ImageDataGenerator\n- Comprehensive evaluation with classification reports and confusion matrices\n\n**Classes Classified:**\nNormal, Ketombe (Dandruff), Alopecia, Skin Inflammation, Folliculitis, Lichen Planus, Male Pattern Baldness, Psoriasis, Seborrheic Dermatitis, Telogen Effluvium, Tinea Capitis, and Head Lice.\n\n**Technical Highlights:**\n- Hybrid PyTorch (GAN) and TensorFlow (CNN) implementation\n- Complete training pipeline with early stopping and model checkpointing\n- Reproducible results with fixed random seeds\n- Extensive EDA with class distribution analysis and sample visualizations\n- Model persistence for inference and deployment",
    "tech": [
      "Python",
      "TensorFlow",
      "Keras",
      "PyTorch",
      "cGAN (Conditional GAN)",
      "VGG16",
      "Deep Learning",
      "Computer Vision",
      "Medical Imaging",
      "NumPy",
      "Pandas",
      "Matplotlib",
      "Seaborn",
      "Scikit-learn",
      "Google Colab",
      "Adam Optimizer",
      "Data Augmentation"
    ],
    "features": [
      "12-Class Scalp Disorder Classification",
      "Conditional GAN for Synthetic Image Generation",
      "Custom VGG16-Style CNN Architecture",
      "Comprehensive Data Preprocessing Pipeline",
      "Automated Data Augmentation (200 images/class)",
      "Training/Validation Split with ImageDataGenerator",
      "Model Checkpointing & Early Stopping",
      "Classification Reports & Confusion Matrix",
      "Visualization of Training Progress",
      "Reproducible Random Seed Management",
      "Google Drive Integration for Data Storage",
      "Exploratory Data Analysis (EDA)",
      "Class Distribution Visualization",
      "Sample Image Visualization Grid"
    ],
    "type": "Deep Learning",
    "category": "computer-vision",
    "link": "/projects/cgan-vgg16-scalp-classification",
    "thumbnail": "/projects/cgan-vgg16-scalp-classification/1.png",
    "gallery": [
      "/projects/cgan-vgg16-scalp-classification/1.png",
      "/projects/cgan-vgg16-scalp-classification/2.png",
      "/projects/cgan-vgg16-scalp-classification/3.png",
      "/projects/cgan-vgg16-scalp-classification/4.png",
      "/projects/cgan-vgg16-scalp-classification/5.png"
    ],
    "demoLink": "#",
    "githubLink": "#"
  }
]